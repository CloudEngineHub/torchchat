Preparing input
Done, Now creating model...
Transformer config: TransformerArgs(block_size=2048, vocab_size=32064, n_layers=32, n_heads=32, dim=4096, hidden_dim=11008, n_local_heads=32, head_dim=128, rope_base=10000, norm_eps=1e-05, multiple_of=256, ffn_dim_multiplier=None, use_tiktoken=False, max_seq_length=768, rope_scaling=None, n_stages=1, stage_idx=0)
Done. Now loading checkpoint...
Done. Now checkpoint remapping...
Done. Now setup caches...
input args for precompute_freqs_cis:
n_elem:  128
seq_len:  4096
base:  10000
dtype:  None
rope_scaling:  None
tensor([1.0000e+00, 8.6596e-01, 7.4989e-01, 6.4938e-01, 5.6234e-01, 4.8697e-01,
        4.2170e-01, 3.6517e-01, 3.1623e-01, 2.7384e-01, 2.3714e-01, 2.0535e-01,
        1.7783e-01, 1.5399e-01, 1.3335e-01, 1.1548e-01, 1.0000e-01, 8.6596e-02,
        7.4989e-02, 6.4938e-02, 5.6234e-02, 4.8697e-02, 4.2170e-02, 3.6517e-02,
        3.1623e-02, 2.7384e-02, 2.3714e-02, 2.0535e-02, 1.7783e-02, 1.5399e-02,
        1.3335e-02, 1.1548e-02, 1.0000e-02, 8.6596e-03, 7.4989e-03, 6.4938e-03,
        5.6234e-03, 4.8697e-03, 4.2170e-03, 3.6517e-03, 3.1623e-03, 2.7384e-03,
        2.3714e-03, 2.0535e-03, 1.7783e-03, 1.5399e-03, 1.3335e-03, 1.1548e-03,
        1.0000e-03, 8.6596e-04, 7.4989e-04, 6.4938e-04, 5.6234e-04, 4.8697e-04,
        4.2170e-04, 3.6517e-04, 3.1623e-04, 2.7384e-04, 2.3714e-04, 2.0535e-04,
        1.7783e-04, 1.5399e-04, 1.3335e-04, 1.1548e-04], device='cuda:0')
tensor([   0,    1,    2,  ..., 4093, 4094, 4095], device='cuda:0')
Done. Now running prefilling inference...
Hidden state before layer 0 is:
torch.Size([1, 636, 4096])
tensor([[[ 0.0045, -0.0038,  0.0017,  ..., -0.0088,  0.0025, -0.0025],
         [-0.0112, -0.0129, -0.0121,  ...,  0.0090,  0.0118, -0.0081],
         [ 0.0195, -0.0058,  0.0061,  ...,  0.0171, -0.0052, -0.0212],
         ...,
         [-0.0187, -0.0017,  0.0177,  ...,  0.0238,  0.0052,  0.0101],
         [ 0.0066, -0.0161,  0.0117,  ..., -0.0103,  0.0148,  0.0073],
         [ 0.0039,  0.0015,  0.0055,  ..., -0.0042,  0.0151,  0.0024]]],
       device='cuda:0', grad_fn=<CatBackward0>)
****************************************************************************************************
q and k, before apply_rotary_emb:
torch.Size([1, 636, 32, 128])
tensor([[[[ 8.8137e-02, -2.7958e-01,  5.8506e-01,  ..., -2.7226e+00,
            1.4709e+00, -2.3085e-01],
          [-1.3625e-01,  2.3757e-01, -5.1018e-01,  ...,  4.1010e-01,
           -5.6383e-01,  4.5404e-01],
          [-3.4834e-03,  3.2426e-01,  3.8369e-01,  ...,  2.9280e-01,
            2.8449e-01,  2.7460e-01],
          ...,
          [ 5.8234e-01, -1.2618e+00, -3.6595e-01,  ...,  1.3358e+00,
            4.3184e-01,  1.0434e+00],
          [ 5.9955e-01,  7.9891e-01, -4.6955e-01,  ..., -4.0199e-01,
            4.2534e-01,  3.9606e-01],
          [-1.1633e+00,  1.2683e+00, -2.0897e-01,  ..., -1.1549e-01,
            5.5778e-01,  1.6868e-01]],

         [[ 1.2024e-01, -1.0154e+00,  1.6093e+00,  ..., -5.5972e-01,
            3.1489e-01, -8.1850e-01],
          [ 4.2993e-01,  2.0342e-01, -1.0682e+00,  ..., -2.5782e-01,
            1.5268e-02, -2.4300e-01],
          [-5.3137e-01, -6.0827e-01, -7.6472e-01,  ..., -3.1512e-01,
           -2.7736e-01, -2.5732e-01],
          ...,
          [ 2.8136e-01, -5.2945e-01, -1.7826e-01,  ...,  1.1955e+00,
            5.4279e-01,  8.5956e-01],
          [ 5.3614e-01,  2.0246e+00, -1.2608e+00,  ..., -3.7489e-01,
            6.3723e-01,  6.5132e-01],
          [-1.8604e+00, -1.2568e+00, -1.6225e+00,  ..., -6.7318e-02,
            1.0279e-01,  9.0100e-02]],

         [[ 7.2795e-02, -1.4323e+00,  2.2321e+00,  ..., -7.5136e-01,
            5.6175e-01, -9.5831e-01],
          [ 1.1465e-01,  1.6517e-01, -4.7936e-01,  ...,  4.2424e-01,
           -9.5693e-01,  5.2483e-01],
          [ 5.8809e-01, -2.5397e-02, -8.4822e-01,  ...,  4.9272e-01,
            4.7836e-01,  5.0513e-01],
          ...,
          [ 4.3381e-01, -3.1210e+00, -1.0508e+00,  ...,  1.3402e+00,
            1.0287e+00,  2.3169e+00],
          [ 9.3764e-01,  2.3067e+00, -1.5072e+00,  ..., -3.8047e-01,
            6.4796e-01,  6.6232e-01],
          [-9.0192e-01, -3.0670e-01, -8.5899e-01,  ..., -1.1170e-01,
            3.3573e-01, -6.0066e-01]],

         ...,

         [[ 1.8439e-01, -1.0198e+00,  1.9433e+00,  ..., -9.0137e-01,
            7.8104e-01, -1.0152e+00],
          [ 1.5872e-01,  8.4707e-02, -6.7571e-01,  ...,  3.9261e-01,
           -6.9446e-01,  4.2872e-01],
          [ 3.6119e-01,  3.0833e-01, -3.7900e-01,  ...,  8.6110e-02,
            8.1632e-02,  1.0222e-01],
          ...,
          [-1.6853e-02, -1.1853e+00, -2.1825e-01,  ...,  1.2019e+00,
            3.7029e-01,  1.3317e+00],
          [ 7.4456e-01,  1.8874e+00, -1.2402e+00,  ..., -3.5604e-01,
            6.1179e-01,  6.2754e-01],
          [-1.2021e+00, -6.7119e-01, -1.1290e+00,  ..., -4.6737e-02,
           -2.0528e-02, -1.7886e-01]],

         [[ 3.5354e-01, -8.3204e-01,  1.7218e+00,  ..., -7.6154e-01,
            6.9443e-01, -8.8789e-01],
          [ 1.0955e-01,  9.3493e-03, -6.4744e-01,  ...,  3.6177e-01,
           -6.0106e-01,  3.8051e-01],
          [ 3.2930e-01,  2.9724e-01, -3.5446e-01,  ..., -1.3412e-03,
           -8.3974e-03,  7.1401e-03],
          ...,
          [-1.1190e-01, -7.5404e-01, -1.2496e-01,  ...,  1.2401e+00,
            3.3029e-01,  1.1143e+00],
          [ 6.3004e-01,  1.7134e+00, -1.1184e+00,  ..., -3.2237e-01,
            5.6728e-01,  5.7957e-01],
          [-1.2236e+00, -6.8457e-01, -1.1400e+00,  ..., -2.8917e-02,
           -2.6101e-02, -1.6053e-01]],

         [[ 2.2438e-01,  4.1760e-01,  3.5730e-01,  ..., -4.1907e-01,
            1.9779e-01, -3.7496e-01],
          [ 3.3656e-01, -5.3128e-02, -1.4364e+00,  ..., -2.9568e-01,
            2.5090e-01, -3.4443e-01],
          [-5.7520e-01, -2.8830e-01, -1.8663e-01,  ..., -3.3193e-01,
           -2.9675e-01, -2.8231e-01],
          ...,
          [ 2.1342e-01, -3.2742e-01, -5.2910e-02,  ...,  1.8387e+00,
            4.8990e-01,  8.7483e-01],
          [ 4.3541e-01,  1.9233e+00, -1.2351e+00,  ..., -3.8134e-01,
            6.0760e-01,  6.1868e-01],
          [-2.0587e+00, -1.5213e+00, -1.8633e+00,  ..., -9.8056e-02,
            1.6597e-01,  3.9716e-01]]]], device='cuda:0',
       grad_fn=<ViewBackward0>)
torch.Size([1, 636, 32, 128])
tensor([[[[-0.4032, -0.0167,  0.0300,  ...,  0.0826, -0.0706, -0.0707],
          [ 1.1458,  0.9121, -0.3251,  ...,  0.5441, -0.2957,  0.5221],
          [ 0.0237, -0.2481, -0.3345,  ..., -0.1705,  0.3765,  0.5979],
          ...,
          [-0.0205, -0.0151,  0.0137,  ...,  0.2737,  0.8049, -0.4081],
          [ 0.1832, -0.4518, -0.2057,  ..., -0.1818,  0.0770,  0.0802],
          [-0.3089,  1.2236,  0.1609,  ...,  0.6910,  0.1255,  0.2735]],

         [[-0.2899, -0.0028,  0.0520,  ...,  0.2636, -0.2013,  0.2681],
          [ 0.6155,  0.8224,  0.3304,  ..., -0.4969,  0.1219, -0.3481],
          [-0.2023,  0.1655,  0.3203,  ...,  1.6260,  1.6661,  1.5222],
          ...,
          [-1.2277, -0.3016, -0.8174,  ..., -0.5467, -0.9489, -1.1181],
          [-0.4164, -0.4066, -0.4455,  ..., -0.3053,  0.0722,  0.0750],
          [ 0.0506, -0.1478, -0.3156,  ..., -1.2014,  0.4634, -0.1019]],

         [[ 0.3341, -0.5947,  0.6357,  ...,  0.0513,  0.2727,  0.1729],
          [ 1.0427,  0.6447, -0.7157,  ..., -0.0696,  0.3202, -0.1045],
          [-0.4113, -0.5721, -0.3090,  ..., -0.4902, -0.5272, -0.4597],
          ...,
          [-0.2218,  0.0770, -0.0610,  ..., -0.1540,  0.4397, -0.2679],
          [ 0.2970, -0.5468, -1.3979,  ...,  0.4245, -0.3060, -0.3003],
          [-1.2661, -1.0212, -1.4402,  ...,  1.4839, -0.7005,  0.4571]],

         ...,

         [[ 0.4322, -0.5403,  0.3777,  ...,  0.1544,  0.0359,  0.1695],
          [ 0.8611,  0.6608, -0.4672,  ...,  0.4453,  0.0383,  0.3679],
          [ 0.1159, -0.2886, -0.3874,  ..., -0.8130, -0.8705, -0.8258],
          ...,
          [-0.5046, -0.0915, -0.3287,  ..., -0.2244, -0.0374, -0.5486],
          [ 0.3189, -0.4997, -0.9601,  ...,  0.3986, -0.3088, -0.3109],
          [-0.6580, -0.5876, -1.0235,  ...,  0.7111, -0.6454,  0.2257]],

         [[-0.0356,  0.1517, -0.2355,  ...,  0.3998, -0.2553,  0.4541],
          [ 0.7241,  0.6216, -0.2981,  ...,  0.3790,  0.0313,  0.3070],
          [ 0.1365, -0.2315, -0.2407,  ..., -0.7944, -0.8674, -0.8289],
          ...,
          [-0.5110, -0.1377, -0.3427,  ..., -0.1021, -0.0801, -0.5258],
          [ 0.2288, -0.2831, -0.8728,  ...,  0.2669, -0.1687, -0.1729],
          [-0.3816, -0.4067, -0.7615,  ...,  0.4735, -0.5601,  0.1255]],

         [[-0.1380, -0.6229,  0.3423,  ...,  0.1316, -0.1960,  0.2663],
          [ 0.6976,  1.1722,  0.2912,  ...,  0.2839, -0.1349,  0.3306],
          [ 0.0694,  0.2533,  0.1255,  ...,  1.4579,  1.5409,  1.4390],
          ...,
          [-1.4628, -0.3196, -1.0152,  ..., -0.4717, -1.1734, -1.2208],
          [-0.5177, -0.4918, -0.5488,  ..., -0.5367,  0.2164,  0.2186],
          [ 0.4723,  0.3053,  0.1405,  ..., -1.6717,  0.3979, -0.3566]]]],
       device='cuda:0', grad_fn=<ViewBackward0>)
q and k, after apply_rotary_emb:
torch.Size([1, 636, 32, 128])
tensor([[[[ 0.0881, -0.2796,  0.5851,  ..., -2.7226,  1.4709, -0.2308],
          [-0.1363,  0.2376, -0.5102,  ...,  0.4101, -0.5638,  0.4540],
          [-0.0035,  0.3243,  0.3837,  ...,  0.2928,  0.2845,  0.2746],
          ...,
          [ 0.5823, -1.2618, -0.3660,  ...,  1.3358,  0.4318,  1.0434],
          [ 0.5995,  0.7989, -0.4695,  ..., -0.4020,  0.4253,  0.3961],
          [-1.1633,  1.2683, -0.2090,  ..., -0.1155,  0.5578,  0.1687]],

         [[ 0.9194, -0.4475,  0.5493,  ..., -0.5596,  0.3150, -0.8185],
          [ 0.0611,  0.4717, -0.4997,  ..., -0.2578,  0.0153, -0.2430],
          [ 0.2247, -0.7758, -0.5275,  ..., -0.3152, -0.2773, -0.2574],
          ...,
          [ 0.5975, -0.0493, -0.0846,  ...,  1.1953,  0.5427,  0.8596],
          [-1.4139,  1.5450,  0.5793,  ..., -0.3748,  0.6372,  0.6514],
          [ 0.0524, -2.2445, -0.1922,  ..., -0.0674,  0.1028,  0.0901]],

         [[ 1.2721,  0.6622, -1.6639,  ..., -0.7511,  0.5620, -0.9582],
          [-0.1979,  0.0355,  0.1847,  ...,  0.4243, -0.9571,  0.5246],
          [-0.2216,  0.5453,  1.0939,  ...,  0.4928,  0.4782,  0.5052],
          ...,
          [ 2.6574,  1.6933, -0.3208,  ...,  1.3397,  1.0281,  2.3172],
          [-2.4877, -0.1074,  2.4119,  ..., -0.3803,  0.6478,  0.6625],
          [ 0.6542, -0.6925,  0.6528,  ..., -0.1118,  0.3359, -0.6006]],

         ...,

         [[-1.0250, -0.1528, -0.9315,  ..., -0.8048,  0.8531, -0.9555],
          [ 0.0798, -0.1613,  0.1087,  ...,  0.3938, -0.7239,  0.3769],
          [ 0.2970, -0.3706,  0.7458,  ...,  0.0809,  0.0739,  0.1079],
          ...,
          [-1.1842,  0.0535, -0.0299,  ...,  1.0856,  0.2720,  1.3552],
          [ 1.8635, -0.8026,  1.8737,  ..., -0.2931,  0.5643,  0.6705],
          [-0.6337,  1.2223,  0.5544,  ..., -0.0724, -0.0074, -0.1799]],

         [[-0.1795, -0.8860, -1.8381,  ..., -0.6720,  0.7575, -0.8347],
          [ 0.0956, -0.0543,  0.5367,  ...,  0.3598, -0.6273,  0.3355],
          [ 0.4397,  0.0586,  0.7529,  ..., -0.0108, -0.0089,  0.0065],
          ...,
          [-0.5191, -0.5583,  0.0824,  ...,  1.1312,  0.2479,  1.1355],
          [ 1.4893,  1.0558,  2.0221,  ..., -0.2650,  0.5234,  0.6195],
          [-1.3962,  0.1283,  1.2648,  ..., -0.0525, -0.0143, -0.1620]],

         [[ 0.0449,  0.4719, -0.3696,  ..., -0.3603,  0.2247, -0.3595],
          [ 0.3308,  0.0816,  1.4085,  ..., -0.2712,  0.2755, -0.3251],
          [-0.4184, -0.4888,  0.2117,  ..., -0.3717, -0.2753, -0.3033],
          ...,
          [ 0.3237, -0.2190,  0.0355,  ...,  1.7209,  0.4245,  0.9084],
          [-0.3446,  1.9417,  1.0332,  ..., -0.3204,  0.5606,  0.6615],
          [-1.3076, -2.2007,  1.7241,  ..., -0.1305,  0.1364,  0.4083]]]],
       device='cuda:0', grad_fn=<ViewBackward0>)
torch.Size([1, 636, 32, 128])
tensor([[[[-0.4032, -0.0167,  0.0300,  ...,  0.0826, -0.0706, -0.0707],
          [ 1.1458,  0.9121, -0.3251,  ...,  0.5441, -0.2957,  0.5221],
          [ 0.0237, -0.2481, -0.3345,  ..., -0.1705,  0.3765,  0.5979],
          ...,
          [-0.0205, -0.0151,  0.0137,  ...,  0.2737,  0.8049, -0.4081],
          [ 0.1832, -0.4518, -0.2057,  ..., -0.1818,  0.0770,  0.0802],
          [-0.3089,  1.2236,  0.1609,  ...,  0.6910,  0.1255,  0.2735]],

         [[-0.1543, -0.2455,  0.4159,  ...,  0.2636, -0.2013,  0.2681],
          [-0.3594,  0.9623,  0.6977,  ..., -0.4968,  0.1220, -0.3481],
          [-0.2486, -0.0808,  0.1940,  ...,  1.6261,  1.6660,  1.5224],
          ...,
          [-0.4096, -1.1961, -1.5964,  ..., -0.5465, -0.9488, -1.1182],
          [ 0.1171, -0.5701, -0.2101,  ..., -0.3053,  0.0722,  0.0750],
          [ 0.1517, -0.0373, -0.1310,  ..., -1.2013,  0.4634, -0.1018]],

         [[ 0.4018,  0.5513, -0.0035,  ...,  0.0514,  0.2727,  0.1729],
          [-1.0201,  0.6798,  0.7916,  ..., -0.0699,  0.3202, -0.1044],
          [ 0.6914, -0.1359, -0.4204,  ..., -0.4903, -0.5271, -0.4598],
          ...,
          [ 0.0223, -0.2337,  0.3496,  ..., -0.1539,  0.4398, -0.2678],
          [ 0.3736,  0.4976,  0.1018,  ...,  0.4244, -0.3059, -0.3004],
          [ 1.4554, -0.7262,  1.1798,  ...,  1.4838, -0.7006,  0.4569]],

         ...,

         [[-0.5534, -0.4153,  0.1699,  ...,  0.1490,  0.0235,  0.1717],
          [ 0.6339, -0.8811,  0.5064,  ...,  0.3630,  0.0113,  0.3697],
          [-0.2921, -0.1069, -0.0323,  ..., -0.8665, -0.8079, -0.8872],
          ...,
          [-0.0759,  0.5072, -0.4380,  ..., -0.1906,  0.0027, -0.5499],
          [-0.5093, -0.3033, -0.3336,  ...,  0.3695, -0.2852, -0.3327],
          [-0.5670,  0.6759,  0.3940,  ...,  0.6923, -0.6601,  0.1780]],

         [[ 0.0565,  0.1452,  0.6558,  ...,  0.3668, -0.2878,  0.4342],
          [ 0.9488,  0.1026,  0.5222,  ...,  0.3105,  0.0088,  0.3085],
          [-0.0185, -0.2681,  0.1706,  ..., -0.8421, -0.8044, -0.8901],
          ...,
          [-0.4992,  0.1758, -0.0446,  ..., -0.0725, -0.0414, -0.5302],
          [ 0.0284, -0.3629,  0.5567,  ...,  0.2499, -0.1556, -0.1848],
          [-0.5448, -0.1193,  0.7166,  ...,  0.4652, -0.5677,  0.0842]],

         [[ 0.1144, -0.6277, -0.3179,  ...,  0.1037, -0.2150,  0.2512],
          [ 0.1883,  1.3510, -0.3788,  ...,  0.3876, -0.1587,  0.3198],
          [-0.0343,  0.2604, -0.1608,  ...,  1.5246,  1.4313,  1.5480],
          ...,
          [-1.2244, -0.8619,  1.1993,  ..., -0.3920, -1.0808, -1.3035],
          [-0.2864, -0.6541,  0.5345,  ..., -0.5218,  0.1998,  0.2339],
          [ 0.3169,  0.4646, -0.0869,  ..., -1.6035,  0.4230, -0.3265]]]],
       device='cuda:0', grad_fn=<ViewBackward0>)
